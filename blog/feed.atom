<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Maks Rafalko</title>
    <link href="https://maks-rafalko.github.io/blog" />
    <link type="application/atom+xml" rel="self" href="https://maks-rafalko.github.io/blog/feed.atom" />
    <updated>2024-07-14T12:22:51+00:00</updated>
    <id>https://maks-rafalko.github.io/blog/feed.atom</id>
    <author>
        <name>Maks Rafalko</name>
    </author>
                <entry>
    <id>https://maks-rafalko.github.io/blog/2024-07-14/eslint-plugin-proper-tests</id>
    <link type="text/html" rel="alternate" href="https://maks-rafalko.github.io/blog/2024-07-14/eslint-plugin-proper-tests" />
    <title>ESLint plugin for writing proper tests</title>
    <published>2024-07-14T00:00:00+00:00</published>
    <updated>2024-07-14T00:00:00+00:00</updated>
    <author>
        <name>Maks Rafalko</name>
    </author>
    <summary type="html">Open Source plugin


no-useless-matcher-to-be-defined
no-useless-matcher-to-be-null
no-mixed-expectation-groups
no-long-arrays-in-test-each

Add more power to your ESLint rules with TypeScript


Recently I joined a project with many typical......</summary>
    <content type="html"><![CDATA[
        <p><img src="https://eslint.org/assets/images/logo/eslint-logo-color.svg" alt="eslint cover"></p>

<ul>
<li><a href="#open-source-plugin">Open Source plugin</a>

<ul>
<li><a href="#no-useless-matcher-to-be-defined">no-useless-matcher-to-be-defined</a></li>
<li><a href="#no-useless-matcher-to-be-null">no-useless-matcher-to-be-null</a></li>
<li><a href="#no-mixed-expectation-groups">no-mixed-expectation-groups</a></li>
<li><a href="#no-long-arrays-in-test-each">no-long-arrays-in-test-each</a></li>
</ul></li>
<li><a href="#add-power-to-eslint-rules-with-typescript">Add more power to your ESLint rules with TypeScript</a></li>
</ul>

<p>Recently I joined a project with many typical microservices, where each one is a standalone NestJS application with many unit and e2e tests.</p>

<p>The good thing - developers write really many tests there, covering all the API endpoints, validation, transactions, etc.</p>

<p>The bad thing - tests were looking messy, so we decided to</p>

<ul>
<li>fix the most popular mistakes and spread best practices across all developers of different microservices</li>
<li>somehow control it, to not allow writing messy tests in the future</li>
</ul>

<p>To achieve the second point in an automatic way, it was decided to write custom ESLint Rules so that developers immediately notified right in their IDE when tests look bad, and which is more important - build is failed if our best practices are not followed.</p>

<p>Below, I would like to show the most interesting rules that I've created and then applied to this work project.</p>

<p><a name="open-source-plugin"></a></p>

<h2>Open Source plugin</h2>

<p><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests"><code>eslint-plugin-proper-tests</code></a> - let's quickly look into some of the rules from this plugin.</p>

<p><a name="no-useless-matcher-to-be-defined"></a></p>

<h3><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/main/docs/rules/no-useless-matcher-to-be-defined.md"><code>no-useless-matcher-to-be-defined</code></a></h3>

<p>This rule disallows using <code>expect(...).toBeDefined()</code> matcher when it is obvious that a variable is always defined.</p>

<p>I was surprised how many times I saw this in the codebases. And I was pretty sure that there should be a rule for this, but seems like not.</p>

<p>As an OSS contributor, I understand that creating new libs/repos is not always a good idea, so I tried to propose this rule for <a href="https://github.com/jest-community/eslint-plugin-jest"><code>eslint-plugin-jest</code></a> (btw, it's awesome!), but for some reason didn't even get a response (and at the time of writing of this post, this is still the case).</p>

<blockquote>
  <p>See original proposal <a href="https://github.com/jest-community/eslint-plugin-jest/issues/1616"><code>eslint-plugin-jest#1616</code></a></p>
</blockquote>

<p>Ok, let's get back to the rule. Here are a couple of real-life examples of bad code:</p>

<pre><code class="language-ts">const response = await request.post(`/api/some-resource`);

expect(response).toBeDefined();
expect(response.status).toBe(200);
</code></pre>

<p>What's the problem with this code? The problem is that <code>expect(response).toBeDefined();</code> always passes and is really the useless check here.</p>

<p>The type of <code>response</code> variable is <code>Response</code>. It physically can not be <code>undefined</code>. Does it make sense to check it with <code>.toBeDefined()</code>? No.</p>

<p>Reported error:</p>

<pre><code class="language-bash">Type of "response" variable is "Response", it can not be undefined. It is useless to check it with `.toBeDefined()` matcher.
</code></pre>

<p>So let's just remove this line:</p>

<pre><code class="language-diff">const response = await request.post(`/api/some-resource`);

- expect(response).toBeDefined();
expect(response.status).toBe(200);
</code></pre>

<p>Another example that is hard to spot looking into the code for the first time:</p>

<pre><code class="language-ts">const response = await request.post(`/api/some-resource`);

// ...

const userCacheKeys = await redisClient.keys('USER_*');

expect(userCacheKeys).toBeDefined();
</code></pre>

<p>The purpose of this test was to check that after calling API endpoint, user's data is cached to Redis. But does it really test anything?</p>

<p>Absolutely no, because the type of <code>userCacheKeys</code> is <code>string[]</code>. So <code>redisClient.keys()</code> <strong>always returns an array</strong>, which is always "defined".</p>

<p>Again, we have expectation that always passes, and which is worse, we don't test anything. Whether Redis has these keys or not - tests don't really catch it.</p>

<p>The proper change for this case is the following:</p>

<pre><code class="language-diff">const userCacheKeys = await redisClient.keys('USER_*');

- expect(userCacheKeys).toBeDefined();

+ const cacheValues = await redisClient.mGet(userCacheKeys);
+
+ expect(cacheValues).toEqual(['cache-value-1', 'cache-value-2']);
</code></pre>

<p>So, now we check the number of keys and exact values returned from Redis. When at some point developers will do a change that will lead to adding new keys or removing keys, such test will catch it, which is what we want.</p>

<blockquote>
  <p><a href="#add-power-to-eslint-rules-with-typescript">Read below</a> to understand how to use TypeScript types to add more power to your ESLint rules</p>
</blockquote>

<p><a name="no-useless-matcher-to-be-null"></a></p>

<h3><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/main/docs/rules/no-useless-matcher-to-be-null.md"><code>no-useless-matcher-to-be-null</code></a></h3>

<p>Similar rule to the previous one, this rule complains where <code>not.toBeNull()</code> is used when it shouldn't:</p>

<pre><code class="language-ts">const user = repository.findByIdOrThrow(123); // return type is `User`

expect(user).not.toBeNull();
</code></pre>

<p>From types point of view, <code>user</code> can not be <code>null</code>, so this check is useless and will be reported by this ESLint rule. Just remove it and replace with a proper expectation.</p>

<p><a name="no-mixed-expectation-groups"></a></p>

<h3><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/main/docs/rules/no-mixed-expectation-groups.md"><code>no-mixed-expectation-groups</code></a></h3>

<p>This rule reports an error if expectations for different variables are mixed with each other.</p>

<p>Here is a very simplified example of a bad test:</p>

<pre><code class="language-ts">const response = await request.post(`/api/some-resource`);

const entity = await repository.getById(123);

expect(response.status).toBe(201);
expect(entity).toMatchObject({...});
expect(response.headers).toMatchObject({...});
expect(response.body).toMatchObject({...});
</code></pre>

<p>In real life when you have multiple lines the things look much worse. So what is the problem here? The problem is that we are checking different variables, mixing them with each other.</p>

<p>Instead, it's better to have "groups" of expectations. The same code can be rewritten like:</p>

<pre><code class="language-ts">const response = await request.post(`/api/some-resource`);

expect(response.status).toBe(201);
expect(response.headers).toMatchObject({...});
expect(response.body).toMatchObject({...});

const entity = await repository.getById(123);

expect(entity).toMatchObject({...});
</code></pre>

<p><a name="no-long-arrays-in-test-each"></a></p>

<h3><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/main/docs/rules/no-long-arrays-in-test-each.md"><code>no-long-arrays-in-test-each</code></a></h3>

<p>This rule disallows the usage of long arrays in <code>test.each()</code> calls.</p>

<p>The following code is bad:</p>

<pre><code class="language-ts">test.each([
  {
    description: 'test case name #1',
    inputValue: 'a',
    expectedOutput: 'aa',
  },
  {
    description: 'test case name #2',
    inputValue: 'b',
    expectedOutput: 'bb',
  },
  {
    description: 'test case name #3',
    inputValue: 'c',
    expectedOutput: 'cc',
  },
  {
    description: 'test case name #4',
    inputValue: 'd',
    expectedOutput: 'dd',
  },
  {
    description: 'test case name #5',
    inputValue: 'e',
    expectedOutput: 'ee',
  },
  {
    description: 'test case name #6',
    inputValue: 'f',
    expectedOutput: 'ff',
  },
])('$description', ({ clientCountry, expectedPaymentMethod, processorName }) =&gt; {
  // ...
});
</code></pre>

<p>Consider extracting such long arrays to a separate files with for example <code>.data.ts</code> postfix.</p>

<p>The following code way better:</p>

<pre><code class="language-ts">// some-service.data.ts
export type TestCase = Readonly&lt;{
  description: string;
  inputValue: string;
  expectedOutput: string;
}&gt;;

export const testCases: TestCase[] = [
  {
    description: 'test case name #1',
    inputValue: 'a',
    expectedOutput: 'aa',
  },
  {
    description: 'test case name #2',
    inputValue: 'b',
    expectedOutput: 'bb',
  },
  {
    description: 'test case name #3',
    inputValue: 'c',
    expectedOutput: 'cc',
  },
  {
    description: 'test case name #4',
    inputValue: 'd',
    expectedOutput: 'dd',
  },
  {
    description: 'test case name #5',
    inputValue: 'e',
    expectedOutput: 'ee',
  },
  {
    description: 'test case name #6',
    inputValue: 'f',
    expectedOutput: 'ff',
  },
];
</code></pre>

<p>and now test is more readable:</p>

<pre><code class="language-ts">test.each(testCases)('$description', ({ inputValue, expectedOutput }: TestCase) =&gt; {
  // ...
});
</code></pre>

<p><a name="add-power-to-eslint-rules-with-typescript"></a></p>

<h2>Add more power to your ESLint rules with TypeScript</h2>

<p><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests"><code>eslint-plugin-proper-tests</code></a> plugin uses TypeScript to provide more accurate results and get the power of TypeScript to understand variables types.</p>

<p>To enable it properly, you need to <a href="https://typescript-eslint.io/getting-started/typed-linting">configure ESLint to work with TypeScript</a>:</p>

<pre><code class="language-ts">// .eslintrc.js

module.exports = {
  "parser": "@typescript-eslint/parser",
  "parserOptions": {
    "project": true,
    "tsconfigRootDir": __dirname,
  }
}
</code></pre>

<p>Now, let's quickly look into how to use TypeScript types to improve your ESLint rules with an example of <a href="#no-useless-matcher-to-be-defined"><code>no-useless-matcher-to-be-defined</code></a> rule.</p>

<blockquote>
  <p>Read official docs on how to use <code>typescript-eslint</code> for typed rules <a href="https://typescript-eslint.io/developers/custom-rules#typed-rules">here</a></p>
</blockquote>

<p>In our rule we need to use <code>typeChecker</code> service:</p>

<pre><code class="language-ts">const services = ESLintUtils.getParserServices(context);
const typeChecker = services.program.getTypeChecker();
</code></pre>

<p><a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/4d7a4a2b9d8ff466c0acb14f79746c6eae5ab9eb/src/custom-rules/no-useless-matcher-to-be-defined.ts#L11C5-L12C59">>> Look into the code</a></p>

<p>Then, to understand if a variable is always defined, we need to:</p>

<ul>
<li>get the type of the variable</li>
<li>check if it can be undefined</li>
</ul>

<p>To get the declaration type of variable, we use the following code:</p>

<pre><code class="language-ts">// argumentNode - is a node of the variable inside expect(variable) call

const symbol = services.getSymbolAtLocation(argumentNode);

const declarationType = typeChecker.getTypeOfSymbolAtLocation(symbol!, symbol!.valueDeclaration!);
</code></pre>

<p>It's a bit tricky, but the good thing you shouldn't do it often. What we did is got the declaration type of the variable.</p>

<p>Now, we need to check if it "contains" <code>undefined</code> sub-type inside (like <code>string | undefined</code>).</p>

<p>For this, I use <code>isTypeFlagSet</code> helper:</p>

<pre><code class="language-ts">const isVariableCanBeUndefined = isTypeFlagSet(
  declarationType,
  ts.TypeFlags.Undefined
);
</code></pre>

<p>which under the hood gets all the union types of a variable and by bit mask checks if <code>undefined</code> is there:</p>

<pre><code class="language-ts">const getTypeFlags = (type: ts.Type): ts.TypeFlags =&gt; {
  let flags: ts.TypeFlags = 0;

  for (const t of tsutils.unionTypeParts(type)) {
    flags |= t.flags;
  }

  return flags;
};

const isTypeFlagSet = (type: ts.Type, flagsToCheck: ts.TypeFlags): boolean =&gt; {
  const flags = getTypeFlags(type);

  return (flags &amp; flagsToCheck) !== 0;
};
</code></pre>

<blockquote>
  <p>Look to the final code <a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/blob/4d7a4a2b9d8ff466c0acb14f79746c6eae5ab9eb/src/custom-rules/no-useless-matcher-to-be-defined.ts#L38-L49">here</a></p>
</blockquote>

<p>This is how you can use TypeScript types to improve your ESLint rules and make them more accurate. Possibilities are endless!</p>

<p>If you like this plugin and the work I'm doing, consider <a href="https://github.com/maks-rafalko/eslint-plugin-proper-tests/">giving it a Star on GitHub</a>.</p>

<p class="my-12 text-center">
    <b>Find this interesting?</b> Let's continue the conversation on <a href="https://x.com/maks_rafalko/status/1804868289732002283" rel="nofollow">Twitter</a>.
</p>
    ]]></content>
</entry>
            <entry>
    <id>https://maks-rafalko.github.io/blog/2024-06-24/linux-windows-mac-performance</id>
    <link type="text/html" rel="alternate" href="https://maks-rafalko.github.io/blog/2024-06-24/linux-windows-mac-performance" />
    <title>Comparing Linux, Windows, Mac performance with Symfony tests suite on Docker</title>
    <published>2024-06-24T00:00:00+00:00</published>
    <updated>2024-06-24T00:00:00+00:00</updated>
    <author>
        <name>Maks Rafalko</name>
    </author>
    <summary type="html">Currently, I have different laptops at home and can compare how fast different test suites can be on 3 Operation Systems:


Windows
Arch Linux (Manjaro)
MacOS


This is not a detailed review of processors and other hardware, rather just my experiments......</summary>
    <content type="html"><![CDATA[
        <p>Currently, I have different laptops at home and can compare how fast different test suites can be on 3 Operation Systems:</p>

<ul>
<li>Windows</li>
<li>Arch Linux (Manjaro)</li>
<li>MacOS</li>
</ul>

<p>This is not a detailed review of processors and other hardware, rather just my experiments and interesting findings with 2 laptops and 3 OSs on them.</p>

<ul>
<li>Laptop 1: Dell XPS 9500 with i7-10750H 10Gen and 64Gb RAM. Release date: May 2020. It has Windows 11 PRO and Arch Linux Manjaro</li>
<li>Laptop 2: MacBook PRO 14" with M3 PRO processor and 36Gb RAM. Release date: end of 2023</li>
</ul>

<h3>Windows with WSL2 with Docker vs native Docker on Linux</h3>

<p>The first experiment is to compare the speed <em>on the same laptop</em> on different OSs.</p>

<p>The first test suite is a Symfony-based project, API-Platform, with 900+ functional (<a href="https://symfony.com/doc/current/testing.html#write-your-first-application-test">application</a>) tests. Tests spin up a real MySQL database, actually 4 databases inside the same container and are executed in 4 threads using <a href="https://github.com/paratestphp/paratest">Paratest</a>. Tests use <code>WebTestCase</code> base class and BrowserKit under the hood.</p>

<p>Before comparing, I assume that Linux with native Docker will have the best performance, so let's start from it and take it as a baseline.</p>

<pre><code class="language-bash">docker compose exec php vendor/bin/paratest -p4 --runner=WrapperRunner
</code></pre>

<p>Results:</p>

<pre><code class="language-bash">[...]
............................................................... 819 / 901 ( 90%)
............................................................... 882 / 901 ( 97%)
...................                                             901 / 901 (100%)

Time: 00:11.493, Memory: 26.00 MB

OK (901 tests, 3914 assertions)
</code></pre>

<p>Pretty nice results. 11 seconds to run almost 1000 functional tests in 4 threads.</p>

<p>Now let's boot into Windows and run the same test suite there.</p>

<p>NOTE: While I write Windows, I work there on WSL2 exclusively. This is a separate topic to speak about, but in a nutshell, you will get the best performance on Windows OS if you do the following:</p>

<ul>
<li>you shouldn't store you code on Windows system, only under WSL2</li>
<li>you shouldn't run docker commands from Windows, only from WSl2</li>
<li>basically, you should do everything from WSL2 and only run IDE from Windows, that can easily connect and edit code stored in WSL2</li>
</ul>

<p>So, I open WSL2 terminal and execute the same command:</p>

<pre><code class="language-bash">docker compose exec php vendor/bin/paratest -p4 --runner=WrapperRunner
</code></pre>

<p>Results:</p>

<pre><code class="language-bash">[...]
............................................................... 819 / 901 ( 90%)
............................................................... 882 / 901 ( 97%)
...................                                             901 / 901 (100%)

Time: 00:11.230, Memory: 27.00 MB

OK (901 tests, 3914 assertions)
</code></pre>

<p>I did it ~10 times and results vary less than by 1s. So 11.2s is an average time, which is <strong>the same speed as on native Linux with Docker</strong>.</p>

<p>Let's sum it up correctly: if you configure Windows to store the source code on WSL2 and work with Docker from there, you will get the same or pretty much the same performance as on native Linux with Docker.</p>

<h3>MacOS with OrbStack/Docker vs Docker on Windows/Linux</h3>

<p>Now, let's compare this tests suite with MacBook Pro 14" with M3 PRO processor and 36Gb RAM.</p>

<p>Instead of Docker, I tried to use <a href="https://orbstack.dev/">OrbStack</a>, which is a drop-in replacement.</p>

<p>Run the command</p>

<pre><code class="language-bash">docker compose exec php vendor/bin/paratest -p4 --runner=WrapperRunner
</code></pre>

<p>and see interesting results:</p>

<pre><code class="language-bash">[...]
............................................................... 819 / 901 ( 90%)
............................................................... 882 / 901 ( 97%)
...................                                             901 / 901 (100%)

Time: 00:05.493, Memory: 26.00 MB

OK (901 tests, 3914 assertions)
</code></pre>

<p>It's 2 times faster than on my Dell laptop, both on Windows and Linux ðŸ˜³</p>

<p>When it takes around 11 seconds on Windows and Linux, it takes only 5 seconds to run 901 functional tests on Mac. Nice results!</p>

<p>Back in 2020, my experiments showed that Docker on Linux was extremely faster than on MacOS (2-3 times faster), but now, with the new M processor, it looks like it's changed. I will keep an eye on it, but very impressed by the results.</p>

<p>Let's do one more comparison with <a href="https://infection.github.io/guide/">Infection</a>'s tests suite: 4000+ unit tests executed in 1 thread using PHPUnit:</p>

<p>Docker on Linux:</p>

<pre><code class="language-bash">[...]
............................................................. 4026 / 4103 ( 98%)
............................................................. 4087 / 4103 ( 99%)
................                                              4103 / 4103 (100%)

Time: 00:12.906, Memory: 100.00 MB

OK, but some tests were skipped!
Tests: 4103, Assertions: 9991, Skipped: 1.
</code></pre>

<p>Docker on Windows under WSL2:</p>

<pre><code class="language-bash">[...]
............................................................. 4026 / 4103 ( 98%)
............................................................. 4087 / 4103 ( 99%)
................                                              4103 / 4103 (100%)

Time: 00:12.822, Memory: 100.00 MB

OK, but some tests were skipped!
Tests: 4103, Assertions: 9991, Skipped: 1.
</code></pre>

<p>OrbStack on MacOS:</p>

<pre><code class="language-bash">[...]
............................................................. 4026 / 4103 ( 98%)
............................................................. 4087 / 4103 ( 99%)
................                                              4103 / 4103 (100%)

Time: 00:06.258, Memory: 96.00 MB

OK, but some tests were skipped!
Tests: 4103, Assertions: 9991, Skipped: 1.
</code></pre>

<p>And again, MacBook with its new M3 PRO processor outperforms Dell XPS with Intel i7-10750H 10gen both on Linux and Windows with WSL2.</p>

<p>Very interesting and promising!</p>

<p class="my-12 text-center">
    <b>Find this interesting?</b> Let's continue the conversation on <a href="https://x.com/maks_rafalko/status/1804868289732002283" rel="nofollow">Twitter</a>.
</p>
    ]]></content>
</entry>
            <entry>
    <id>https://maks-rafalko.github.io/blog/2021-11-21/symfony-tests-performance</id>
    <link type="text/html" rel="alternate" href="https://maks-rafalko.github.io/blog/2021-11-21/symfony-tests-performance" />
    <title>Improve Symfony Tests Performance</title>
    <published>2021-11-21T00:00:00+00:00</published>
    <updated>2021-11-21T00:00:00+00:00</updated>
    <author>
        <name>Maks Rafalko</name>
    </author>
    <summary type="html">Using more simple password hashers
Do not use Doctrine logging by default
Set &lt;code&gt;APP_DEBUG&lt;/code&gt; to &lt;code&gt;false&lt;/code&gt;
Completely disable Xdebug
Parallel tests execution using Paratest
Collect coverage with &lt;code&gt;pcov&lt;/code&gt; if possible
Collect......</summary>
    <content type="html"><![CDATA[
        <ul>
<li><a href="#using-more-simple-password-hasher">Using more simple password hashers</a></li>
<li><a href="#do-not-use-doctrine-logging-by-default">Do not use Doctrine logging by default</a></li>
<li><a href="#set-app-debug-false">Set <code>APP_DEBUG</code> to <code>false</code></a></li>
<li><a href="#completely-disable-xdebug">Completely disable Xdebug</a></li>
<li><a href="#parallel-tests-execution-using-paratest">Parallel tests execution using Paratest</a></li>
<li><a href="#collect-coverage-with-pcov-if-possible">Collect coverage with <code>pcov</code> if possible</a></li>
<li><a href="#collect-coverage-with-cache-directory">Collect coverage with <code>cacheDirectory</code></a></li>
<li><a href="#miscellaneous">Miscellaneous</a>

<ul>
<li><a href="#dama-doctrine-test-bundle">Use <code>dama/doctrine-test-bundle</code> to rollback transaction after each test</a></li>
<li><a href="#prefer-unit-tests">Combine functional &amp; unit tests. Prefer Unit tests</a></li>
</ul></li>
</ul>

<p>For all the latest Symfony projects at my company we were writing unit and mostly functional tests, occasionally improving their performance, but didn't have a chance to summarize all the improvements we made to speed up the test suite.</p>

<p>In this article, I will show the most comprehensive list of tips and tricks to decrease tests time, resource consumption and improve their speed.</p>

<p>First, let's start with our baseline for one of the projects.</p>

<ul>
<li><code>2285</code> - the total number of tests</li>
<li><code>979</code> unit tests</li>
<li><code>1306</code> functional tests (Symfony's <code>WebTestCase</code>, testing API endpoints)</li>
<li>Symfony 5.3, PHP 8.1</li>
</ul>

<p>The whole test suite <em>before</em> optimizations takes: <code>Time: 12:25.512, Memory: 551.01 MB</code>.</p>

<p>Why having a fast and reliable tests suite is important? There a lot of reasons, but 2 main are:</p>

<ol>
<li>The more tests suite takes to be executed, the more annoying it is for a developer</li>
<li>The more resources (CPU, Memory) tests suite takes, the worse it is for CI server (it can slow down other jobs/builds) and eventually for our Planet</li>
</ol>

<p>Let's see what we can do here.</p>

<p><a name="using-more-simple-password-hasher"></a></p>

<h2>Using more simple password hasher</h2>

<p>Password hashers are used in Symfony to hash the raw password during persisting the User to database and to verify password validity. For production, we have to use <a href="https://symfony.com/doc/current/security/passwords.html#supported-algorithms">more reliable</a> hashing algorithms which are quite slow by their nature (Argon2, bcrypt, etc.).</p>

<p>While checking 1 password during login is not a big deal, imaging hashing passwords thousands of times during tests execution. This becomes a bottleneck.</p>

<p>Instead of using mentioned hashing algorithms, we can use <code>md5</code> for <code>test</code> environment and increase the speed of the test suite.</p>

<pre><code class="language-yaml"># config/packages/security.yaml for dev &amp; prod env
security:
    password_hashers:
      App\Entity\User:
        algorithm: argon2i


# override in config/packages/test/security.yaml for test env
security:
    password_hashers:
        App\Entity\User:
            algorithm: md5
            encode_as_base64: false
            iterations: 0
</code></pre>

<p>Let's run <code>phpunit</code> again and check the results:</p>

<pre><code class="language-bash">vendor/bin/phpunit

# ...

Time: 05:32.496, Memory: 551.00 MB
</code></pre>

<p>What an improvement!</p>

<pre><code class="language-diff">- Time: 12:25.512, Memory: 551.01 MB
+ Time: 05:32.496, Memory: 551.00 MB
</code></pre>

<p>It is 2.25x faster than it was before just by changing hashing function. This is one of the most valuable performance optimization that can be done in minutes, and, to be honest, I don't know why it isn't forced by big players like API-Platform or Symfony itself in their distributions. Let's try to change that and help other developers to not waste time: <a href="https://github.com/api-platform/docs/pull/1472">api-platform/docs#1472</a>, <a href="https://github.com/symfony/recipes/issues/1024">symfony/recipes#1024</a>.</p>

<p><a name="do-not-use-doctrine-logging-by-default"></a></p>

<h2>Do not use Doctrine logging by default</h2>

<p>After a couple of years working with the test suite with disabled Doctrine logging, we didn't experience any inconveniences. When there is an error thrown, stack trace will have a failed SQL query in the log/output anyway. So for tests execution, there is no really a need to log SQL queries to the log file, as in most cases you will need them only in case of errors, which already works as mentioned above.</p>

<p>Let's disable doctrine logging for the <code>test</code> environment:</p>

<pre><code class="language-yaml"># config/packages/test/doctrine.yaml
doctrine:
    dbal:
        logging: false
</code></pre>

<p>Run the tests again and compare with the previous results:</p>

<pre><code class="language-diff">- Time: 05:32.496, Memory: 551.00 MB
+ Time: 04:13.959, Memory: 547.01 MB
</code></pre>

<p>Such an easy change and another minute is gone. This improvement highly depends on how you use the (monolog) logger for <code>test</code> environment. General tip: do not log too much for tests. For example, setting log level <code>debug</code> is not necessary, and for tests you <a href="https://github.com/api-platform/api-platform/blob/ac68010c818bde422b97a7044b8df04176e970a4/api/config/packages/test/monolog.yaml#L5">can use</a> production-like configuration - <code>fingercrossed</code> handler with <code>action: error</code>.</p>

<p><a name="set-app-debug-false"></a></p>

<h2>Set <code>APP_DEBUG</code> to <code>false</code></h2>

<p>It was proposed <a href="https://github.com/symfony/recipes/pull/530">back in 2019</a> by <strong>@javiereguiluz</strong>, but didn't get enough popularity. Though, now Symfony's documentation mentions this improvement in a <a href="https://symfony.com/doc/current/testing.html#set-up-your-test-environment">"Set-up your Test Environment"</a> paragraph:</p>

<blockquote>
  <p>It is recommended to run your test with <code>debug</code> set to <code>false</code> on your CI server, as it significantly improves test performance.</p>
</blockquote>

<p>To disable debug mode, add the following line to your <code>phpunit.xml</code> file:</p>

<pre><code class="language-xml">&lt;?xml version="1.0" encoding="UTF-8"?&gt;

&lt;phpunit &gt;
    &lt;php&gt;
        &lt;!--  ..... --&gt;
        &lt;server name="APP_DEBUG" value="false" /&gt;
    &lt;/php&gt;
&lt;/phpunit&gt;

</code></pre>

<p>Disabling <code>debug</code> mode also disables clearing the cache. And if your tests don't run in a clean environment each time (for example tests are executed locally, where you always change the source files), you have to manually clear the cache each time <code>PHPUnit</code> is executed.</p>

<p>This is how it looks like on our project inside <code>PHPUnit</code>'s <code>bootstrap</code> file:</p>

<pre><code class="language-php">&lt;?php

use Symfony\Component\Filesystem\Filesystem;

require dirname(__DIR__).'/vendor/autoload.php';

// ...

(new Filesystem())-&gt;remove([__DIR__ . '/../var/cache/test']);

echo "\nTest cache cleared\n";
</code></pre>

<p>We can live with this "inconvenience", especially with the benefit it gets. Ready to see the results?</p>

<pre><code class="language-diff">- Time: 04:13.959, Memory: 547.01 MB
+ Time: 02:45.307, Memory: 473.00 MB
</code></pre>

<p>Besides the speed, there is one more (I think major) benefit of using <code>APP_DEBUG=false</code>. Functional tests start responding with <code>Internal Server Error</code> rather than with an exception message thrown from the source code.</p>

<p>This can be a dealbreaker in Symfony projects. I saw a couple of projects, where people used the following code:</p>

<pre><code class="language-php"># App\Controller\SomeController.php

throw new ConflictHttpException('There is a conflict between X and Y');
</code></pre>

<p>asserting in tests that response contains exactly this exception message <code>There is a conflict between X and Y</code> in functional tests when <code>APP_DEBUG=true</code>, while in fact the response message is <code>The server returned a "409 Conflict".</code> with <code>APP_DEBUG=false</code>, and test start failing after using <code>APP_DEBUG=false</code>.</p>

<p>Using <code>APP_DEBUG=false</code> with functional tests is a <em>right way</em> from errors/exceptions points of view and this mimics a real production environment.</p>

<p>Again, to save developers' time, let's try to change API-Platform distribution and Symfony's <code>phpunit-bridge</code> recipe and add this behavior by default: <a href="https://github.com/api-platform/api-platform/pull/2078">api-platform/api-platform#2078</a>, <a href="https://github.com/symfony/recipes/issues/1025">symfony/recipes#1025</a></p>

<p><a name="completely-disable-xdebug"></a></p>

<h2>Completely disable Xdebug</h2>

<p>Many of us install <code>Xdebug</code> for debugging purposes, adding it to the base development docker images or right to the local machine. If you use <code>pcov</code> to collect a coverage or <em>even if you don't collect coverage at all</em>, <code>Xdebug</code> can still impact a performance of the test suite, even if you use <code>xdebug.mode=debug</code> but not <code>xdebug.mode=coverage</code>.</p>

<p>So make sure to completely disable <code>Xdebug</code> before running your tests:</p>

<pre><code class="language-bash">XDEBUG_MODE=off vendor/bin/phpunit
</code></pre>

<p>For our project, we managed to get a great performance boost by applying this approach on development environment:</p>

<pre><code class="language-diff">- Time: 02:45.307, Memory: 473.00 MB
+ Time: 01:47.368, Memory: 449.00 MB
</code></pre>

<blockquote>
  <p>There is no need to install <code>Xdebug</code> on CI if you collect coverage with <code>pcov</code>, so in our case CI was not affected.</p>
</blockquote>

<p>Moreover, we did the same for many other commands in our <code>Makefile</code>, for example:</p>

<pre><code class="language-bash"># Makefile
DISABLE_XDEBUG=XDEBUG_MODE=off

app-reinstall: prerequisites ## Setup application database with fixtures
    $(DISABLE_XDEBUG) bin/console doctrine:database:drop --force --if-exists
    $(DISABLE_XDEBUG) bin/console doctrine:database:create
    $(DISABLE_XDEBUG) bin/console doctrine:schema:update --force
    $(DISABLE_XDEBUG) bin/console doctrine:fixtures:load -n
</code></pre>

<p><strong>Note:</strong> There are a number of OSS tools that use <a href="https://github.com/composer/xdebug-handler"><code>composer/xdebug-handler</code></a> that can <em>automatically</em> disable <code>Xdebug</code> and re-run the process. From my point of view - this is very convenient and it should be used if possible for such tools as PHP Magic Detector, PHP-CS-Fixer, etc. Basically, for static analysis tools.</p>

<blockquote>
  <p>Do not use <code>Xdebug</code> for collecting code coverage unless you need a <a href="https://doug.codes/php-code-coverage#branch-coverage"><code>path</code>/<code>branch</code> coverage</a>. Use <code>pcov</code> instead (explained below)</p>
</blockquote>

<p><a name="parallel-tests-execution-using-paratest"></a></p>

<h2>Parallel tests execution using Paratest</h2>

<p>Every good tool has an option to be executed in parallel (to name a few: <code>Psalm</code>, <code>PHPStan</code>, <code>Infection</code>). To get all the power from multicore processor of your local machine or CI server, make sure to run your tests in parallel as well.</p>

<p>Personally, I recommend using <a href="https://github.com/paratestphp/paratest"><code>Paratest</code></a>. It is a wrapper for <code>PHPUnit</code> that just works, even code coverage can be collected and combined from different threads.</p>

<p>If you use DB for your functional tests, you will have to set up as many DB schemas as threads you want to use in <code>Paratest</code>. This library <a href="https://github.com/paratestphp/paratest#test-token">exposes</a> a <code>TEST_TOKEN=&lt;int&gt;</code> environment variable that can be used to determine what DB connection to use.</p>

<p>Imaging you run your tests with 4 threads, so you need 4 DB schemas and 4 different DB connections:</p>

<pre><code class="language-bash">vendor/bin/paratest --processes=4 --runner=WrapperRunner
</code></pre>

<p>To configure Doctrine to use different connections, the following config can be used:</p>

<pre><code class="language-yaml"># config/packages/test/doctrine.yaml

parameters:
    test_token: 1

doctrine:
    dbal:
        dbname: 'db_%env(default:test_token:TEST_TOKEN)%'
</code></pre>

<p>In this case, depending on <code>TEST_TOKEN</code> variable, <code>PHPUnit</code> will run an application connected to different databases: <code>db_1</code>, <code>db_2</code>, <code>db_3</code>, <code>db_4</code>.</p>

<p>Why is it needed? Because tests, executed simultaneously for the same DB, can break each other: they can rewrite or remove the same data, transactions can be time outed or locked. Thus, running tests in isolation - when each thread uses its own DB - fixes this issue.</p>

<p>Running a test suite with 4 threads for our project gives the following performance boost:</p>

<pre><code class="language-diff">- Time: 01:47.368, Memory: 449.00 MB
+ Time: 00:34.256, Memory: 40.00 MB
</code></pre>

<p>Do you remember we started with <code>Time: 12:25.512, Memory: 551.01 MB</code>?</p>

<p>After all the changes, it's <code>Time: 00:34.256, Memory: 40.00 MB</code>! This is <strong>21x faster</strong> than it was in the beginning.</p>

<p><a name="collect-coverage-with-pcov-if-possible"></a></p>

<h2>Collect coverage with <code>pcov</code> if possible</h2>

<p>Now, let's see how we can improve the speed of the test suite when we collect coverage data. To make it more visible, let's step back and run our test suite without <code>Paratest</code>, using 1 thread in <code>PHPUnit</code> with <code>Xdebug</code> and then <code>pcov</code> as a coverage driver.</p>

<pre><code class="language-diff">- Time: 03:49.987, Memory: 575.00 MB # Xdebug
+ Time: 02:13.209, Memory: 519.01 MB # pcov
</code></pre>

<p>As we can see, for this particular case <code>pcov</code> is 1.72x faster than <code>Xdebug</code>. Depending on your project, you can get even better results (e.g. <a href="https://dev.to/swashata/setup-php-pcov-for-5-times-faster-phpunit-code-coverage-3d9c">5x times faster</a>)</p>

<p><code>pcov</code> <a href="https://github.com/krakjoe/pcov#differences-in-reporting">has a comparable accuracy</a> in coverage reports with <code>Xdebug</code>, so this should be a great choice unless you need a path/branch coverage (which are not supported by <code>pcov</code>).</p>

<p><a name="collect-coverage-with-cache-directory"></a></p>

<h2>Collect coverage with <code>cacheDirectory</code></h2>

<p>As <a href="https://github.com/paratestphp/paratest#generating-code-coverage">suggested</a> in the Paratest repository:</p>

<blockquote>
  <p>Beginning from <code>PHPUnit</code> 9.3.4, it is strongly advised to set a coverage cache directory, see <a href="https://github.com/sebastianbergmann/phpunit/blob/9.3.4/ChangeLog-9.3.md#934---2020-08-10">PHPUnit Changelog @ 9.3.4</a>.</p>
</blockquote>

<p>Before doing this update, let's see how much time does it take to run <code>PHPUnit</code> with collecting coverage metrics:</p>

<pre><code class="language-bash">XDEBUG_MODE=off vendor/bin/paratest -p4 --runner=WrapperRunner --coverage-clover=reports/coverage.xml --coverage-html=reports

...

Time: 01:02.904, Memory: 478.93 MB
Generating code coverage report ... done [00:10.796]
</code></pre>

<p>Total time with code coverage reports generating is 1m 13s.</p>

<p>Now, let's add a <code>cacheDirectory</code> in <code>phpunit.xml</code> file:</p>

<pre><code class="language-diff">- &lt;coverage&gt;
+ &lt;coverage cacheDirectory=".coverage-cache"&gt;
</code></pre>

<p>and run <code>PHPUnit</code> with collecting code coverage again. Here are the results:</p>

<pre><code class="language-diff">- Time: 01:02.904, Memory: 478.93 MB
- Generating code coverage report ... done [00:10.796]
+ Time: 00:43.759, Memory: 475.70 MB
+ Generating code coverage report ... done [00:05.394]
</code></pre>

<p>Nice, much faster now. On a real big tests suite, we were able to decrease the time from 11 minutes to 5 minutes on CI thanks to <code>cacheDirectory</code> setting.</p>

<blockquote>
  <p>Read more about how it works under the hood in a post by Sebastian Bergmann: <a href="https://thephp.cc/articles/caching-makes-everything-faster-right">https://thephp.cc/articles/caching-makes-everything-faster-right</a></p>
</blockquote>

<p><a name="miscellaneous"></a></p>

<h2>Miscellaneous</h2>

<p><a name="dama-doctrine-test-bundle"></a></p>

<h3>Use <code>dama/doctrine-test-bundle</code> to rollback transaction after each test</h3>

<p>There are many ways on how to work with a database in functional tests, including setting up DB schema <em>before</em> each test case (on <code>setUp()</code> method), truncating only changed tables <em>after</em> each test case and so on.</p>

<p>Things we should be aware of:</p>

<ol>
<li>We <strong>should not</strong> setup DB schema for each test. This is a one-time operation before tests are started.</li>
<li>We <strong>should not</strong> insert required for application work data for each test. Examples: lookup tables, administrator user, countries and states. Basically, everything that is static and stored in the DB - should be inserted one time before tests are started. This data should be reused across all the functional tests.</li>
</ol>

<p>When these 2 points are done, all we need to do is to restore DB to the same state that it was when a test case started. And here is when <a href="https://github.com/dmaicher/doctrine-test-bundle"><code>dama/doctrine-test-bundle</code></a> comes into play.</p>

<p>It decorates a Doctrine database connection and starts a transaction <em>before</em> each test then rolls it back <em>after</em> it. By doing a <code>ROLLBACK</code>, each test leaves a database in its initial state after execution, while during the test we can do whatever we want - inserts, updates, deletes and searches.</p>

<blockquote>
  <p>This results in a performance boost as there is no need to rebuild the schema, import a backup SQL dump or re-insert fixtures before every testcase.</p>
</blockquote>

<p>As always, results depend on your project, but <a href="https://locastic.com/blog/speed-up-database-refreshing-in-phpunit-tests/">here is an example</a> of 40% performance improvement by using this bundle/approach.</p>

<p><a name="prefer-unit-tests"></a></p>

<h3>Combine functional &amp; unit tests. Prefer Unit tests</h3>

<p>Functional tests are very powerful, as they not just test independent <em>unit</em> of code, but test how things work together. For example, if you are testing API endpoints, you can test the whole flow of your application: from <code>Request</code> to <code>Response</code>.</p>

<p>However, testing every single condition and line of code only by functional tests is expensive, as it requires too many slow tests.</p>

<p>Imagine, we have an API endpoint for getting Order details: <code>GET /orders/{id}</code>. And the following business rules should apply:</p>

<ul>
<li><code>Admin</code> <strong>can</strong> view Order details</li>
<li><code>Manager</code> <strong>can</strong> view Order details</li>
<li><code>User</code> who placed this Order <strong>can</strong> view Order details</li>
<li><code>User</code> who was given shared access but not placed this Order <strong>can</strong> view Order details</li>
<li>Any other authenticated <code>User</code> <strong>can not</strong> view Order details</li>
<li>Not authenticated <code>User</code> <strong>can not</strong> view Order details</li>
</ul>

<p>API endpoint is protected by Security check:</p>

<pre><code class="language-php">#[IsGranted('ORDER_VIEW', object)]
public function viewOrder(Order $order) { /* ... */ }
</code></pre>

<p>To cover these requirements, we need to write at least 6 tests. But instead of creating 6 slow functional tests, we can create 2, just to check that action in a controller is protected by <code>#[IsGranted]</code> attribute.</p>

<pre><code class="language-php">public function test_guest_user_can_not_view_order_details(): void
{
    $order = $this-&gt;createOrder();

    // send request by guest user
    $this-&gt;sendRequest(Request::METHOD_GET, sprintf('/api/orders/%s', $order-&gt;getId()));

    $this-&gt;assertRequestIsForbidden();
}

public function test_admin_user_can_view_order_details(): void
{
    $this-&gt;logInAsAdministrator();

    $order = $this-&gt;createOrder();

    // send request by administrator user
    $this-&gt;sendRequest(Request::METHOD_GET, sprintf('/api/orders/%s', $order-&gt;getId()));

    $this-&gt;assertResponseStatusCodeSame(Response::HTTP_OK);
}
</code></pre>

<p>All other cases can be checked in <strong>Unit</strong> tests for Security Voter and its logic. With this approach, we know that our voter is being called during API call (functional test checks it), and all the conditions/branches are covered by fast unit tests.</p>

<p>To give you an idea about how fast unit tests are (from a real project discussed above):</p>

<pre><code class="language-bash">XDEBUG_MODE=off vendor/bin/phpunit --testsuite=Unit

Time: 00:00.750, Memory: 66.01 MB

OK (979 tests, 2073 assertions)
</code></pre>

<p>So <code>979</code> unit tests take less than <code>1s</code> to be executed in 1 thread, while <code>1306</code> functional tests take <code>1m 46s</code> in 1 thread. For this case, unit tests are <strong>105x</strong> times faster. While 1 functional test is being executed, we can run 100 unit tests!</p>

<p>Also, having more unit tests makes Mutation Testing (<a href="https://infection.github.io/guide/">Infection</a>) work <em>much</em> faster for your project, while functional tests slows down this process.</p>

<hr />

<p>Credits &amp; related articles:</p>

<ul>
<li><a href="https://titouangalopin.com/posts/60edL3P43zwG6uGUiIlvPL/tips-for-a-reliable-and-fast-test-suite-with-symfony-and-doctrine">https://titouangalopin.com/posts/60edL3P43zwG6uGUiIlvPL/tips-for-a-reliable-and-fast-test-suite-with-symfony-and-doctrine</a></li>
<li><a href="https://codewave.eu/blog/how-to-reduce-time-symfony-integration-tests">https://codewave.eu/blog/how-to-reduce-time-symfony-integration-tests</a></li>
<li><a href="https://habr.com/ru/post/505736/">https://habr.com/ru/post/505736/</a></li>
</ul>

<p class="my-12 text-center">
    <b>Find this interesting?</b> Let's continue the conversation on <a href="https://twitter.com/maks_rafalko" rel="nofollow">Twitter</a>.
</p>
    ]]></content>
</entry>
    </feed>
